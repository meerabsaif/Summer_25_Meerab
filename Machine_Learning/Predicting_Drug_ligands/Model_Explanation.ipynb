{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e805293-ba8b-4fab-9097-f9a86842a67a",
   "metadata": {},
   "source": [
    "## ML-Project 1\n",
    "## <span style=\"color:maroon\"> **Predicting Drug-like Ligands Using Molecular Descriptors and Atom Encodings**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef34d6b-cd74-4bcb-a3dd-e1200da8cd08",
   "metadata": {},
   "source": [
    "This project helps in finding potential drugs by predicting molecules that are drug-like. By using molecular descriptors and machine learning, we can screen thousands of molecules without testing each of them in the lab. It can save lots of time and money. Feature importance plot also tells which chemical properties are most important, which can help in designing better and more effective drugs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c195ca9-4cbb-4b76-bdb7-d368e6000c05",
   "metadata": {},
   "source": [
    "## What is Drug-Likeness?\n",
    "\n",
    "> Drug-likeness tells if a molecule has properties that make it suitable to be a drug. Drugs should absorb well in the body, be safe and effective.\n",
    "> Lipinski’s Rule of Five is used to check if a molecule has drug like qualities. \n",
    "> In this project, a computer learned patterns from molecules that are drugs and non-drugs. Then, it predicted new molecules based on those patterns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bce6af-ea89-4c87-888d-76a0daa9a962",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "1. **Read molecule data** from .sdf files that contain information about drug-like and non-drug-like molecules.\n",
    "2. **Extracted molecular descriptors** to understand the molecule's chemical behavior.\n",
    "3. **Trained a machine learning model** to predict if a molecule is drug-like or not.\n",
    "4. **Evaluated the model** to see how well it works and saved the results for analysis.\n",
    "5. **Created visualizations** to understand the model’s performance and most important properties.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033bf3e0-80fd-4644-bd3a-35f6411fd34e",
   "metadata": {},
   "source": [
    "### 1. Labelling \n",
    "- Created a table with the file paths, molecule names, and labels.\n",
    "- The labels (1 or 0) are answers model learned to predict.\n",
    "\n",
    "### 2. Molecular Descriptor Properties\n",
    "  - **Molecular Weight (Mol_Weight)**: How heavy the molecule is.\n",
    "  - **LogP**: How well the molecule dissolves in fat (important for absorption in the body).\n",
    "  - **HBD (Hydrogen Bond Donors)**: How many parts of the molecule can donate hydrogen bonds (affects how it binds to proteins).\n",
    "  - **HBA (Hydrogen Bond Acceptors)**: How many parts can accept hydrogen bonds.\n",
    "  - **TPSA (Topological Polar Surface Area)**: How polar (water-attracting) the molecule is.\n",
    "  - **Rotatable Bonds (RB)**: How flexible the molecule is.\n",
    "  - **Aromatic Rings**: How many stable ring structures (like benzene) it has.\n",
    "  - **Rings**: Total number of ring structures.\n",
    "  - **Fsp3**: Fraction of carbon atoms with sp3 hybridization (affects 3D shape).\n",
    "  - **Heteroatoms**: Non-carbon, non-hydrogen atoms (like oxygen or nitrogen).\n",
    "  - **BertzCT**: How complex the molecule’s structure is.\n",
    "  - **Heavy Atoms**: Number of non-hydrogen atoms.\n",
    "- These properties describe a molecule’s size, shape, solubility, and chemical behavior, which determine if it can work as a drug. Drugs need to be small enough to enter cells but not too big as big drugs cause side effects.\n",
    "- **Biological reasoning**: These properties affect how a molecule moves through the body, binds to targets (like proteins), and avoids toxicity. LogP tells if a molecule can pass through cell membranes and TPSA tells how well it will dissolve in water.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5e7a73-fd15-4ab1-9261-7099c26148b7",
   "metadata": {},
   "source": [
    "### 3. Checking Lipinski’s Rule of Five\n",
    "- I counted how many times a molecule violates Lipinski’s rules. Rules:\n",
    "  - Molecular weight less than 500.\n",
    "  - LogP fat solubility is less than 5.\n",
    "  - Hydrogen bond donors less than 5.\n",
    "  - Hydrogen bond acceptors less than 10.\n",
    "- If a molecule violates too many rules (more than 2), it cannot be a drug.\n",
    "- For example, too many hydrogen bond donors make the molecule stick to water and not let it enter cells.\n",
    "\n",
    "### 4. Preparing Data for Machine Learning\n",
    "- Split the data into features and labels. I also removed any rows with missing or invalid data.\n",
    "- Model needs clean data to learn patterns. Features are inputs and labels are the outputs to be predicted.\n",
    "\n",
    "### 5. Performing 5-Fold Cross-Validation\n",
    "- Data spilt into 5 parts, training on 4 parts, and testing on the remaining 1 part. Repeated this 5 times, each time a different part for testing is used.\n",
    "- Checks if the model works well on unseen data. This prevents overfitting.\n",
    "- The average accuracy from the 5 tests gives the model’s reliability.\n",
    "\n",
    "### 6. Training the Random Forest Model\n",
    "- Random Forest Classifier uses many decision trees to make predictions. \n",
    "- It is good at finding patterns in complex data. It’s reliable and less likely to overfit compared to other models.\n",
    "- Molecular properties interact in complex ways. This model handles these interactions well. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17622378-e8ac-40ef-b09b-a80a700b28f3",
   "metadata": {},
   "source": [
    "### 7. Making Predictions\n",
    "- The model predicted if test molecules were drug-like or non-drug-like and saved the results to “predictions.csv”.\n",
    "\n",
    "### 8. Evaluating the Model\n",
    "- Several metrics were used to check the model’s performance. \n",
    "  - **Confusion Matrix**: Table showing correct and incorrect predictions (True Positives, True Negatives, False Positives, False Negatives).\n",
    "  - **Classification Report**: Includes precision (how many predicted drugs are actually drugs), recall (how many actual drugs were predicted correctly), and F1-score (a balance of precision and recall).\n",
    "  - **Accuracy**: Percentage of correct predictions.\n",
    "  - **Mean Absolute Error (MAE)**: Average difference between predicted and actual labels.\n",
    "  - **Mean Squared Error (MSE)**: Similar to MAE but squares the errors (less useful for classification).\n",
    "- Metrics tell me how well the model works. Accuracy shows overall correctness, precision makes sure we havent I don’t mislabeled non-drugs as drugs, and recall makes sure we havent missed actual drugs. MAE and MSE give extra details about errors.\n",
    "\n",
    "- **Biological reasoning**: Accurate predictions reduce the cost of testing bad molecules and they increase the chance of finding effective drugs.\n",
    "\n",
    "### 9. Visualizing Results\n",
    "- I created two graphs:\n",
    "  - **Confusion Matrix Heatmap** (saved as “confusion_matrix.png”): A colorful grid showing correct and incorrect predictions.\n",
    "  - **Feature Importance Bar Plot** (saved as “feature_importance.png”): A bar graph showing which molecular descriptors matter most for predictions.\n",
    "- Heatmap makes it easy to see how many predictions were correct or wrong. The bar plot shows which properties are most important in deciding if a molecule is drug-like.\n",
    "\n",
    "## Output Files and there content\n",
    "\n",
    "1. **finaldataset.csv**:\n",
    "   - Contains the full dataset with molecule names and all related information. \n",
    "   - **Purpose**: This file saves all the data I used for training and analysis, to reuse easily. \n",
    "\n",
    "2. **predictions.csv**:\n",
    "   - Contains predictions for the test set, including: file paths, molecule names, actual labels, and predicted labels.\n",
    "   - **Purpose**: To tell how well model predicted on new data. \n",
    "\n",
    "3. **confusion_matrix.png**:\n",
    "   - A heatmap showing the number of correct and incorrect predictions.\n",
    "   - **Analysis**: If heatmap shows high numbers on top-left and bottom-right, the model is accurate. Small numbers in non diagonal cells mean fewer errors.\n",
    "\n",
    "4. **feature_importance.png**:\n",
    "   - A bar plot showing which molecular descriptors are most important for predictions.\n",
    "   - **Analysis**: Taller bars indicate more important features. This helps focus on optimizing these properties in drug design.\n",
    "\n",
    "## Metrics details\n",
    "\n",
    "- **Confusion Matrix Heatmap**: The model is good at identifying both drugs and non-drugs.\n",
    "\n",
    "- **Feature Importance Bar Plot**: LogP or TPSA have high importance, the model relies on fat solubility or polarity to decide drug-likeness. These properties affect how a molecule moves through the body and interacts with cells.\n",
    "\n",
    "- **Classification Report**: \n",
    "  - **Precision**: How many molecules I predicted as drugs were actually drugs. High precision means fewer false positives, which is important to avoid wasting time on bad molecules.\n",
    "  - **Recall**: How many actual drugs I correctly predicted. High recall means I’m not missing good drugs.\n",
    "  - **F1-score**: A balance between precision and recall, useful when both are important.\n",
    "  - **Accuracy**: The overall percentage of correct predictions. If accuracy is 1 (100%), it might mean the data is unbalanced (see below).\n",
    "\n",
    "- **Accuracy of 1 and Unbalanced Data**:\n",
    "- The model’s accuracy is 1 (100%), it might mean the data is unbalanced. This happened because the model correctly predicted all test molecules (as seen in “predictions.csv”).\n",
    "  - Unbalanced data means I have way more drug-like molecules than non-drug-like molecules. The model might predict “drug” every time and get high accuracy but it’s not learning properly.\n",
    "  - The dataset should have a similar number of drug-like and non-drug-like molecules (50% each or close). This helps the model learn patterns for both groups equally.\n",
    "  - To fix unbalanced data next time I can collect more non drug-like molecules or use techniques like:\n",
    "  -  oversampling (adding copies of non-drugs) or undersampling (removing some drugs).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bbecc4-051f-4a6a-bb42-9393738e90fa",
   "metadata": {},
   "source": [
    "# Analysis and Conclusion of My Drug-Likeness Prediction Project\n",
    "## Analysis of the Results\n",
    "\n",
    "### 1. Dataset Overview \n",
    "The file contains 61 molecules with their chemical properties (41 drug-like molecules and 20 non-drug-like molecules.\n",
    "- **Drug-like molecules**: Usually have smaller weights compared to some non-drug-like molecules.\n",
    "- **LogP**: Drug-like molecules have balanced solubility while non-drug-like molecules like decane are very fat-soluble.\n",
    "- **Lipinski Violations**: Most drug-like molecules have 0–2 violations while non-drug-like molecules like insulin (3) or digoxin (3) have more, they’re less likely to be drugs.\n",
    "- **TPSA**: Drug-like molecules have moderate TPSA while non-drug-like molecules like insulin have extreme values.\n",
    "- **Fsp3**: Non-drug-like molecules like alkanes have high Fsp3 (simple structures) while drug-like molecules like ibuprofen have more complex shapes.\n",
    "- **Data Imbalance**: There are 41 drug-like and 20 non-drug-like molecules (2:1 ratio), this makes the model favor drug-like predictions.\n",
    "\n",
    "### 2. Model Predictions \n",
    "The file shows predictions for 14 test molecules. The model got all 14 correct, with 100% accuracy.\n",
    "\n",
    "- **Perfect Accuracy**: The model got every prediction right.\n",
    "\n",
    "  - The test set is small (14 molecules), so it does not show models true ability.\n",
    "  - Dataset is imbalanced.\n",
    "  - The model might have memorized the data instead of learning general patterns, called overfitting. \n",
    "\n",
    " Correct predictions are good for drug discovery, but perfect accuracy says that model might not work correctly on new and different molecules.\n",
    "\n",
    "### 3. Confusion Matrix  \n",
    "\n",
    "- Since the model got 100% accuracy, matrix shows:\n",
    "  - High numbers on the diagonal (correct predictions for drugs and non-drugs)\n",
    "  - Zero errors (no false positives or false negatives).\n",
    "- The heatmap’s dark diagonal (in blue colour) shows all predictions are correct.\n",
    "\n",
    "### 4. Feature Importance \n",
    "The feature importance bar plot shows which chemical properties the model used most to make predictions.\n",
    "\n",
    "**What I Found**:\n",
    "- important properties::\n",
    "  - **LogP**: How fat-soluble a molecule is, critical for passing through cell membranes.\n",
    "  - **TPSA**: How polar a molecule is, affecting how it dissolves in the body.\n",
    "  - **Molecular Weight**: How big the molecule is, impacting absorption.\n",
    "  - **Lipinski_Violations**: How many drug-likeness rules the molecule breaks.\n",
    "- Less important properties can be **Aromatic** or **Rings** , vary less between drugs and non-drugs.\n",
    "\n",
    "- LogP and TPSA are key as they decide how a molecule moves through the body.\n",
    "\n",
    "### 5. Evaluation Metrics \n",
    "- **Accuracy**: 1.0 (100%) as all predictions are correct.\n",
    "- **Classification Report**:\n",
    "  - **Precision**: 1.0 (all predicted drugs are drugs, all predicted non-drugs are non-drugs).\n",
    "  - **Recall**: 1.0 (correctly predicted actual values).\n",
    "  - **F1-score**: 1.0 (balance of precision and recall).\n",
    "- **Mean Absolute Error (MAE)**: 0 (no errors).\n",
    "- **Mean Squared Error (MSE)**:  0 \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db840bb4-b278-44ad-ad22-d2ba36272e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
